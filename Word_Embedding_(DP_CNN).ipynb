{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install gensim==4.3.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"aK5Sr6RQv19N","outputId":"e165d696-09d0-4fee-a4b9-bac5f4e09ac3","executionInfo":{"status":"ok","timestamp":1742661951884,"user_tz":-420,"elapsed":45589,"user":{"displayName":"Huy Tr·∫ßn","userId":"00486687804615904934"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim==4.3.0\n","  Downloading gensim-4.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.0) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.0) (1.14.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.0) (7.1.0)\n","Collecting FuzzyTM>=0.4.0 (from gensim==4.3.0)\n","  Downloading FuzzyTM-2.0.9-py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from FuzzyTM>=0.4.0->gensim==4.3.0) (2.2.2)\n","Collecting pyfume (from FuzzyTM>=0.4.0->gensim==4.3.0)\n","  Downloading pyFUME-0.3.4-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim==4.3.0) (1.17.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim==4.3.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim==4.3.0) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim==4.3.0) (2025.1)\n","Collecting scipy>=1.7.0 (from gensim==4.3.0)\n","  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m880.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy>=1.18.5 (from gensim==4.3.0)\n","  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Collecting simpful==2.12.0 (from pyfume->FuzzyTM>=0.4.0->gensim==4.3.0)\n","  Downloading simpful-2.12.0-py3-none-any.whl.metadata (4.8 kB)\n","Collecting fst-pso==1.8.1 (from pyfume->FuzzyTM>=0.4.0->gensim==4.3.0)\n","  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pandas (from FuzzyTM>=0.4.0->gensim==4.3.0)\n","  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting miniful (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim==4.3.0)\n","  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim==4.3.0) (1.17.0)\n","Downloading gensim-4.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading FuzzyTM-2.0.9-py3-none-any.whl (31 kB)\n","Downloading pyFUME-0.3.4-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading simpful-2.12.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: fst-pso, miniful\n","  Building wheel for fst-pso (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20430 sha256=9ec5f64331f5ddf9a1dcda4b75b24e7b2d809cc09541f25c0c33acc903566816\n","  Stored in directory: /root/.cache/pip/wheels/69/f5/e5/18ad53fe1ed6b2af9fad05ec052e4acbac8e92441df44bad2e\n","  Building wheel for miniful (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3507 sha256=d96a7af0cdb46df08406e5931d6fd583ce2e7f7bc2c8dd107cf458667cfb3990\n","  Stored in directory: /root/.cache/pip/wheels/9d/ff/2f/afe4cd56f47de147407705626517d68bea0f3b74eb1fb168e6\n","Successfully built fst-pso miniful\n","Installing collected packages: numpy, scipy, pandas, simpful, miniful, fst-pso, pyfume, FuzzyTM, gensim\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.14.1\n","    Uninstalling scipy-1.14.1:\n","      Successfully uninstalled scipy-1.14.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n","mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n","jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n","jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n","xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n","jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n","jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n","dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n","plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n","blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n","pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n","scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n","dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","cvxpy 1.6.4 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed FuzzyTM-2.0.9 fst-pso-1.8.1 gensim-4.3.0 miniful-0.0.6 numpy-1.24.4 pandas-1.5.3 pyfume-0.3.4 scipy-1.10.1 simpful-2.12.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"eb580627260d413dae9ef8d15c439dab"}},"metadata":{}}]},{"cell_type":"code","source":["import pickle\n","from gensim.models import Word2Vec\n","import numpy as np\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","file_path = '/content/drive/MyDrive/Colab Notebooks/NLP/Task DP-CNN/dp_cnn_tokens.pkl'\n","\n","\n","# M·ªü v√† ƒë·ªçc d·ªØ li·ªáu t·ª´ file .pkl\n","with open(file_path, 'rb') as f:\n","    data = pickle.load(f)\n","\n","# Gi·∫£ s·ª≠ 'data' ch·ª©a c√°c kh√≥a 'train_tokens' v√† 'test_tokens' nh∆∞ t·ª´ ƒëi·ªÉn\n","train_tokens = data['train_tokens']\n","test_tokens = data['test_tokens']\n","val_tokens = data['val_tokens']"],"metadata":{"id":"dYyt3c1AuqmS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742662059062,"user_tz":-420,"elapsed":22362,"user":{"displayName":"Huy Tr·∫ßn","userId":"00486687804615904934"}},"outputId":"7b72149a-cdb4-489f-df59-9dae31250276"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","\n","# T·∫°o danh s√°ch t·∫•t c·∫£ token t·ª´ c√°c file trong t·∫≠p train\n","all_sentences = list(train_tokens.values())  # M·ªói file l√† m·ªôt danh s√°ch token\n","\n","# Hu·∫•n luy·ªán m√¥ h√¨nh Word2Vec\n","word2vec_model = Word2Vec(sentences=all_sentences, vector_size=30, window=5, min_count=1, workers=4)\n","\n","# L·∫•y danh s√°ch token ph·ªï bi·∫øn nh·∫•t trong Word2Vec\n","top_tokens = list(word2vec_model.wv.index_to_key)[:10]\n","\n","# Ch·ªçn m·ªôt token b·∫•t k·ª≥ ƒë·ªÉ ki·ªÉm tra\n","sample_token = top_tokens[1] if top_tokens else None\n","\n","if sample_token:\n","    print(f\"Vector c·ªßa token '{sample_token}':\\n{word2vec_model.wv[sample_token]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lEhm7MrNu72L","outputId":"603612ae-16df-4d3c-c110-6e19887c4b59","executionInfo":{"status":"ok","timestamp":1742662060521,"user_tz":-420,"elapsed":1457,"user":{"displayName":"Huy Tr·∫ßn","userId":"00486687804615904934"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector c·ªßa token '<RETURN>':\n","[-1.0158436  -0.60524035  1.9724342   0.08814531 -0.3852217  -0.39393735\n","  1.3229451   0.815394   -1.4410672  -0.39808413  1.660108    0.21830828\n","  0.4051605  -1.0566111  -0.44229773 -1.4093052   0.42097414  0.67398983\n"," -2.0631337   1.3903568  -0.9638187   0.10557427 -0.28721297  2.2844765\n","  1.1519322   1.1712509   0.606368    0.78285456  0.02403784 -2.7176857 ]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","MAX_SEQUENCE_LENGTH = 100  # S·ªë token t·ªëi ƒëa m·ªói file\n","EMBEDDING_DIM = 30  # K√≠ch th∆∞·ªõc vector embedding\n","\n","def encode_tokens(tokens, max_length=MAX_SEQUENCE_LENGTH):\n","    \"\"\"Chuy·ªÉn token th√†nh vector embedding, padding n·∫øu thi·∫øu\"\"\"\n","    encoded = np.zeros((max_length, EMBEDDING_DIM))  # Ma tr·∫≠n ƒë·∫ßu v√†o\n","    for i, token in enumerate(tokens[:max_length]):  # Gi·ªõi h·∫°n max_length\n","        if token in word2vec_model.wv:\n","            encoded[i] = word2vec_model.wv[token]\n","    return encoded\n","\n","# üîπ 1. M√£ h√≥a d·ªØ li·ªáu train v√† test\n","X_train = np.array([encode_tokens(tokens) for tokens in train_tokens.values()])\n","X_val = np.array([encode_tokens(tokens) for tokens in val_tokens.values()])\n","X_test = np.array([encode_tokens(tokens) for tokens in test_tokens.values()])\n","\n","print(f\"üìå D·ªØ li·ªáu train shape: {X_train.shape}\")\n","print(f\"üìå D·ªØ li·ªáu val shape: {X_val.shape}\")\n","print(f\"üìå D·ªØ li·ªáu test shape: {X_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4JzzcMauvHwB","outputId":"09bb3023-fbb7-488a-e3e4-fd25c78779cd","executionInfo":{"status":"ok","timestamp":1742662061028,"user_tz":-420,"elapsed":506,"user":{"displayName":"Huy Tr·∫ßn","userId":"00486687804615904934"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["üìå D·ªØ li·ªáu train shape: (225, 100, 30)\n","üìå D·ªØ li·ªáu val shape: (57, 100, 30)\n","üìå D·ªØ li·ªáu test shape: (342, 100, 30)\n"]}]},{"cell_type":"code","source":["# üîπ 1. Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# üîπ 2. ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n l∆∞u file\n","save_dir = \"/content/drive/MyDrive/Colab Notebooks/NLP/Task DP-CNN/\"\n","save_path = os.path.join(save_dir, \"dp_cnn_embeddings.pkl\")\n","\n","# üîπ 3. T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# üîπ 5. L∆∞u file v√†o th∆∞ m·ª•c trong Google Drive\n","data = {\n","    \"X_train_embeddings\": X_train,\n","    \"X_test_embeddings\": X_test,\n","    \"X_val_embeddings\": X_val\n","}\n","\n","with open(save_path, \"wb\") as f:\n","    pickle.dump(data, f)\n","\n","print(f\"‚úÖ File ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {save_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4KVZ6fJwZVa","outputId":"fd7c1610-c2d2-40a9-83bb-7280716a5942","executionInfo":{"status":"ok","timestamp":1742662063633,"user_tz":-420,"elapsed":2602,"user":{"displayName":"Huy Tr·∫ßn","userId":"00486687804615904934"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","‚úÖ File ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: /content/drive/MyDrive/Colab Notebooks/NLP/Task DP-CNN/dp_cnn_embeddings.pkl\n"]}]}]}